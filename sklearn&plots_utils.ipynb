{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_variance(df):\n",
    "    \"\"\"\n",
    "    remove columns with variance <= threshold\n",
    "    \"\"\"\n",
    "    selector = VarianceThreshold(threshold=0.0)\n",
    "    selector.fit(df)\n",
    "    df_transformed = df[df.columns[selector.get_support(indices=True)]]\n",
    "    return df_transformed\n",
    "\n",
    "\n",
    "def remove_low_variance_wmeta(df, cols_meta):\n",
    "    \"\"\"\n",
    "    remove columns with variance <= threshold\n",
    "    \"\"\"\n",
    "    selector = VarianceThreshold(threshold=0.0)\n",
    "    selector.fit(df.drop(columns=cols_meta))\n",
    "    df_transformed = df[df.columns[selector.get_support(indices=True)]]\n",
    "    df_transformed[cols_meta] = df[cols_meta]\n",
    "    return df_transformed\n",
    "\n",
    "\n",
    "def remove_zeros_rows(df, cols):\n",
    "    return df.loc[(df[cols]!=0).any(axis=1)]\n",
    "\n",
    "\n",
    "def std_scaler(df):\n",
    "    sc = StandardScaler()\n",
    "    return pd.DataFrame(sc.fit_transform(df.values),columns=df.columns)\n",
    "\n",
    "\n",
    "def rs_scaler(df):\n",
    "    rsc = RobustScaler()\n",
    "    return pd.DataFrame(rsc.fit_transform(df.values),columns=df.columns)\n",
    "\n",
    "\n",
    "def text_tfidf(df):\n",
    "    vec = TfidfVectorizer()\n",
    "    X = vec.fit_transform(df.values)\n",
    "    return pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "  \n",
    "\n",
    "def cols_eda(df): \n",
    "    eda_df = {}\n",
    "    eda_df['null_sum'] = df.isnull().sum()\n",
    "    eda_df['null_%'] = df.isnull().mean()\n",
    "    eda_df['dtypes'] = df.dtypes\n",
    "    eda_df['count'] = df.count()\n",
    "    eda_df['mean'] = df.mean()\n",
    "    eda_df['median'] = df.median()\n",
    "    eda_df['min'] = df.min()\n",
    "    eda_df['max'] = df.max()\n",
    "    return pd.DataFrame(eda_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>blue</td>\n",
       "      <td>una mattina</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>medium</td>\n",
       "      <td>green</td>\n",
       "      <td>mi son svegliato</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>red</td>\n",
       "      <td>o bella ciao</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "      <td>purple</td>\n",
       "      <td>bella ciao</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bella ciao</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    f1   f2  f3      f4      f5                f6 id  label\n",
       "0  2.0  4.0   1     low    blue       una mattina  a      1\n",
       "1  NaN  NaN   1  medium   green  mi son svegliato  b      0\n",
       "2  3.0  6.0   1     NaN     red      o bella ciao  c      1\n",
       "3  4.0  7.0   1    high  purple        bella ciao  d      1\n",
       "4  NaN  8.0   1     low     NaN        bella ciao  e      1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {\n",
    "    'id':['a','b','c','d','e'], \n",
    "    'f1':[2,np.nan,3,4,np.nan], \n",
    "    'f2':[4,np.nan,6,7,8], \n",
    "    'f3':[1,1,1,1,1],           \n",
    "    'f4':['low','medium',np.nan,'high','low'], \n",
    "    'f5':['blue','green','red','purple',np.nan], \n",
    "    'f6':['una mattina','mi son svegliato','o bella ciao','bella ciao','bella ciao'],\n",
    "    'label':[1,0,1,1,1]\n",
    "}\n",
    "df = pd.DataFrame(dict_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f4</th>\n",
       "      <th>bella</th>\n",
       "      <th>ciao</th>\n",
       "      <th>mattina</th>\n",
       "      <th>mi</th>\n",
       "      <th>son</th>\n",
       "      <th>svegliato</th>\n",
       "      <th>una</th>\n",
       "      <th>f5_green</th>\n",
       "      <th>f5_missing</th>\n",
       "      <th>f5_purple</th>\n",
       "      <th>f5_red</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.581139</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1   f2  f4     bella      ciao   mattina       mi      son  \\\n",
       "0 -1.581139 -2.5   1  0.000000  0.000000  0.707107  0.00000  0.00000   \n",
       "1  0.000000  0.0   2  0.000000  0.000000  0.000000  0.57735  0.57735   \n",
       "2  0.000000 -0.5   0  0.707107  0.707107  0.000000  0.00000  0.00000   \n",
       "3  1.581139  0.5   3  0.707107  0.707107  0.000000  0.00000  0.00000   \n",
       "4  0.000000  1.5   1  0.707107  0.707107  0.000000  0.00000  0.00000   \n",
       "\n",
       "   svegliato       una  f5_green  f5_missing  f5_purple  f5_red id  label  \n",
       "0    0.00000  0.707107         0           0          0       0  a      1  \n",
       "1    0.57735  0.000000         1           0          0       0  b      0  \n",
       "2    0.00000  0.000000         0           0          0       1  c      1  \n",
       "3    0.00000  0.000000         0           0          1       0  d      1  \n",
       "4    0.00000  0.000000         0           1          0       0  e      1  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars = ['f1', 'f2', 'f3']\n",
    "cat_vars = ['f4', 'f5', 'f6']\n",
    "meta_vars = ['id','label']\n",
    "\n",
    "# numerical variables\n",
    "df_num = df[num_vars].copy()\n",
    "df_num.fillna(df_num.median(), inplace=True)\n",
    "df_num = remove_low_variance(df_num)\n",
    "df_num = std_scaler(df_num) # standard scaler, YOU DO NOT NEED THIS FOR RANDOM FOREST\n",
    "df_num = rs_scaler(df_num) # robust scaler, YOU DO NOT NEED THIS FOR RANDOM FOREST\n",
    "\n",
    "# categorical variables\n",
    "df_cat = df[cat_vars].copy()\n",
    "df_cat.fillna('missing', inplace=True)\n",
    "## ordinal\n",
    "cat = pd.Categorical(df_cat.f4, categories=['missing', 'low', 'medium', 'high'], ordered=True)\n",
    "labels, unique = pd.factorize(cat, sort=True)\n",
    "df_cat.f4 = labels\n",
    "## text\n",
    "df_cat_text = text_tfidf(df_cat.f6)\n",
    "df_cat = pd.concat([df_cat.drop('f6', axis=1), df_cat_text], axis=1)\n",
    "## cardinal\n",
    "df_cat = pd.get_dummies(df_cat, drop_first=True)\n",
    "\n",
    "# put df back together\n",
    "df_final = pd.concat([df_num, df_cat, df[meta_vars]], axis=1)\n",
    "df_final\n",
    "\n",
    "\n",
    "# # EDA\n",
    "cols_eda(df)\n",
    "\n",
    "\n",
    "# under sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X, y = rus.fit_sample(df_final.drop('label', axis=1), df_final['label'])\n",
    "df_balanced = pd.concat([X,y], axis=1)\n",
    "df_balanced\n",
    "\n",
    "\n",
    "# PCA\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "X_pca = PCA(n_components=16).fit_transform(X_std)\n",
    "\n",
    "\n",
    "# # remove low variance with meta\n",
    "# cols_meta = ['id','label']\n",
    "# df = remove_low_variance(df, cols_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, auc, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label','id'], axis=1)\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(oob_score=True)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(f'training accuracy: {forest.score(X_train, y_train)}')\n",
    "print(f'oob score: {forest.oob_score_}')\n",
    "\n",
    "print(f'test accuracy: {forest.score(X_test, y_test)}')\n",
    "y_pred = forest.predict(X_test)\n",
    "pred_probs = forest.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search with oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(params, x, y):\n",
    "        oob_score = 0\n",
    "        best_params = {}\n",
    "        print('hyperparameters tuning starts...')\n",
    "        for n in tqdm(params['n_estimators']):\n",
    "            for max_ in params['max_depth']:\n",
    "                for min_ in params['min_samples_leaf']:\n",
    "                    for max_f in params['max_features']:\n",
    "                        for min_split in params['min_samples_split']:\n",
    "                            for criterion in params['criterion']:\n",
    "                                forest = RandomForestClassifier(criterion=criterion, n_estimators=n, max_depth=max_,\n",
    "                                                                min_samples_leaf=min_, min_samples_split=min_split,\n",
    "                                                                max_features=max_f,\n",
    "                                                                random_state=params['random_state'], n_jobs=-1,\n",
    "                                                                oob_score=params['oob_score'])\n",
    "                                forest.fit(x, y)\n",
    "                                if forest.oob_score_ > oob_score:\n",
    "                                    print(f'updated OOB score: {forest.oob_score_}')\n",
    "                                    oob_score = forest.oob_score_\n",
    "                                    best_params['n_estimators'] = n\n",
    "                                    best_params['max_depth'] = max_\n",
    "                                    best_params['min_samples_leaf'] = min_\n",
    "                                    best_params['max_features'] = max_f\n",
    "                                    best_params['min_samples_split'] = min_split\n",
    "                                    best_params['criterion'] = criterion\n",
    "        print(f'best OOB score is {oob_score}')\n",
    "        print(f'best parameters {best_params}')\n",
    "\n",
    "        forest = RandomForestClassifier(criterion=best_params['criterion'], n_estimators=best_params['n_estimators'],\n",
    "                                        max_depth=best_params['max_depth'],\n",
    "                                        min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                        min_samples_split=best_params['min_samples_split'],\n",
    "                                        max_features=best_params['max_features'],\n",
    "                                        random_state=self.random_state, n_jobs=-1,\n",
    "                                        oob_score=self.oob_score)\n",
    "        return forest.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth':[None],\n",
    "    'max_features':['auto'],\n",
    "    'min_samples_leaf': [2],\n",
    "    'n_estimators': [100, 1000],\n",
    "    'min_samples_split': [2],\n",
    "    'criterion':['entropy'],\n",
    "    'random_state':42,\n",
    "    'oob_score': True\n",
    "}\n",
    "\n",
    "forest = grid_search(params, X_train, y_train)\n",
    "\n",
    "print(f'The training accuracy is {forest.score(X_train, y_train)}')\n",
    "print(f'The test accuracy is {forest.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(df, forest, n):\n",
    "    features = df.columns\n",
    "    importances = forest.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.bar(np.arange(0,n,1), importances[indices[:n]], align='center', width=.5, alpha=.5, linewidth=1.0, edgecolor='k',\n",
    "           label='individual feature importance')\n",
    "    plt.step(np.arange(0,n,1), np.cumsum(importances[indices[:n]]), where='mid', label='cumulative feature importance')\n",
    "    plt.xticks(np.arange(0,n,1), features[indices[:n]], rotation=90)\n",
    "    plt.ylabel('Importance')\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(X_train, forest, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confmat(y_true, y_pred):\n",
    "    confmat = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = sns.heatmap(confmat, annot=True, annot_kws={'size':20}, fmt=\".0f\", \n",
    "                linewidths=.5, square = True, cmap = 'Blues', cbar_kws={\"shrink\": .5})\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    plt.tick_params(axis='both', labelsize=20)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    plt.text(2, 0.5, classification_report(y_true, y_pred, target_names=['Failure [0]', 'Success [1]']), size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confmat(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC_curve(y_true, pred_probs):\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, pred_probs, pos_label=1)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f'ROC (area= %.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', linewidth=3, color=(0.6, 0.6, 0.6), label='random guessing')\n",
    "        plt.plot([0, 0, 1], [0, 1, 1], linestyle=':', linewidth=3, color='k', label='perfect performance')\n",
    "        plt.xlim([-0.05, 1.05])\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.xlabel('false positive rate', size=20)\n",
    "        plt.ylabel('true positive rate', size=20)\n",
    "        plt.legend(loc=\"lower right\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC_curve(y_test, pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probs(probs0, probs1):\n",
    "        fig = plt.figure(figsize=(10,6))\n",
    "        sns.distplot(probs0, hist=False, kde_kws={\"shade\": True}, label='Failure')\n",
    "        sns.distplot(probs1, hist=False, kde_kws={\"shade\": True}, label='Success')\n",
    "        plt.xlabel('Probability of success', size=20)\n",
    "        plt.legend(loc='best', fontsize=15)\n",
    "        plt.xlim([0.0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = pd.DataFrame({'y_true':y_test.values, 'probs':pred_probs})\n",
    "probs0 = df_probs[df_probs.y_true==0].probs\n",
    "probs1 = df_probs[df_probs.y_true==1].probs\n",
    "plot_probs(probs0, probs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool)) # mask to have just a triangular matrix\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(250, 9, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-0.7, vmax=0.7, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corrwith(df['Target']).iloc[:-1].to_frame() # you should have features only and label as last column in df\n",
    "correlations['abs'] = correlations[0].abs()\n",
    "sorted_correlations = correlations.sort_values('abs', ascending=False)[0]\n",
    "fig, ax = plt.subplots(figsize=(6,10))\n",
    "sns.heatmap(sorted_correlations[:10].to_frame(), cmap='coolwarm', annot=True, vmin=-0.75, vmax=0.75, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most correlated features distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12)) # this is for 9 plots\n",
    "for i, col in enumerate(sorted_correlations.index[:9]):\n",
    "    sns.distplot(df[df['Target']==0][col], label='0', ax=axes[i//3][i%3])\n",
    "    sns.distplot(df[df['Target']==1][col], label='1', ax=axes[i//3][i%3])\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('label', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dist plots with cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "kwargs = {'cumulative': True, \"histtype\": \"step\"}\n",
    "sns.distplot(df.FEATURE, hist_kws=kwargs, kde=False, bins=75, label='cumulative FEATURE')\n",
    "sns.distplot(df.FEATURE, kde=False, bins=75, label='individual FEATURE')\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "plt.xlim([0,1400])\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar plots with hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "splot = sns.barplot('date', 'count', hue='game_name', data=df)\n",
    "for item in splot.get_xticklabels():\n",
    "    item.set_rotation(45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
